经过预训练，LLM 此时已经掌握了大量知识，然而此时它只会无脑地词语接龙，还不会与人聊天。

SFT 阶段就需要把半成品 LLM 施加一个自定义的聊天模板进行微调，称这个过程为指令微调。
例如模型遇到这样的模板【问题->回答，问题->回答】后不再无脑接龙，而是意识到这是一段完整的对话结束。

### 微调数据集
minimind 作者对 匠数大模型SFT数据集 和 Magpie-SFT数据集 进行了数据清洗（只保留中文字符占比高的内容），筛选长度<512的对话，得到sft_mini_512.jsonl(~1.2GB)。