压缩主要分为以下 4 种技术
- 剪枝（Pruning）：移除模型中不必要或多余的组件，比如参数，以使模型更加高效；
- 知识蒸馏（Knowledge Distillation）：从一个复杂的模型（称为教师模型）向一个简化的模型（称为学生模型）转移知识来实现；
- 量化（Quantization）：将传统的表示方法中的浮点数转换为整数或其他离散形式，以减轻深度学习模型的存储和计算负担；
- 低秩分解（Low-Rank Factorization）：低秩分解旨在通过将给定的权重矩阵分解成两个或多个较小维度的矩阵，从而对其进行近似。

### 剪枝（Pruning）

### 知识蒸馏（Knowledge Distillation）

### 量化（Quantization）

### 低秩分解（Low-Rank Factorization）

### Reference
- 大模型压缩首篇综述来啦~：https://zhuanlan.zhihu.com/p/652434165
- 大模型知识蒸馏概述：https://zhuanlan.zhihu.com/p/659943824